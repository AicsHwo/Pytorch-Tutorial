{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 101 - 004\n",
    "#### *Date* : 2019.05.01\n",
    "#### *Auther* :`Jen-Huan Hu`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comfirm cuda device via ***torch.cuda*** commands :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if cuda device exists via 'torch.cuda.device_count()' : 1\n",
      "Check current device via 'torch.cuda.current_device()' : 0\n",
      "Check cuda device #1 via 'torch.cuda.device(0)' : <torch.cuda.device object at 0x000002020101BB00>\n",
      "Check cuda device #1 name via 'torch.cuda.get_device_name(0)' : GeForce GTX 1060 with Max-Q Design\n",
      "Try 'torch.cuda.get_device_capability(0)' : (6, 1)\n",
      "Try 'torch.cuda.get_device_properties(0)' : _CudaDeviceProperties(name='GeForce GTX 1060 with Max-Q Design', major=6, minor=1, total_memory=6144MB, multi_processor_count=10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Check if cuda device exists via 'torch.cuda.device_count()' : {}\".format( torch.cuda.device_count() ))\n",
    "print(\"Check current device via 'torch.cuda.current_device()' : {}\".format( torch.cuda.current_device() ))\n",
    "print(\"Check cuda device #1 via 'torch.cuda.device(0)' : {}\".format( torch.cuda.device(0) ))\n",
    "print(\"Check cuda device #1 name via 'torch.cuda.get_device_name(0)' : {}\".format( torch.cuda.get_device_name(0)) )\n",
    "print(\"Try 'torch.cuda.get_device_capability(0)' : {}\".format( torch.cuda.get_device_capability(0) ))\n",
    "print(\"Try 'torch.cuda.get_device_properties(0)' : {}\".format( torch.cuda.get_device_properties(0) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For any torch vector, make it to reside in either cpu or cuda device via ***<torch.tensor>.to()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch device using cuda\n",
      "a = tensor([-10.0000,  -7.5000,  -5.0000,  -2.5000,   0.0000,   2.5000,   5.0000,\n",
      "          7.5000], dtype=torch.float64)\n",
      "a.device = cpu\n",
      "b = tensor([[ 0.3226, -0.0261,  0.8072],\n",
      "        [-0.6731, -0.8248, -0.8590],\n",
      "        [-2.0269,  1.9285,  1.1771],\n",
      "        [-2.6445,  1.5218,  1.6197],\n",
      "        [-0.7643,  0.4250, -1.4369]])\n",
      "b.device = cpu\n",
      "a = tensor([-10.0000,  -7.5000,  -5.0000,  -2.5000,   0.0000,   2.5000,   5.0000,\n",
      "          7.5000], device='cuda:0', dtype=torch.float64)\n",
      "a.device = cuda:0\n",
      "c.device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.device_count() else 'cpu'\n",
    "print('torch device using {}'.format( device ))\n",
    "\n",
    "a = torch.tensor(np.arange(-10., 10., 2.5))\n",
    "b = torch.randn((5, 3))\n",
    "c = torch.tensor(np.array([1,2,3,4,5]), device = device)\n",
    "print(\"a = %s\" % a)\n",
    "print(\"a.device = %s\" % a.device)\n",
    "print(\"b = %s\" % b)\n",
    "print(\"b.device = %s\" % b.device)\n",
    "a = a.to('cuda')\n",
    "print(\"a = %s\" % a)\n",
    "print(\"a.device = %s\" % a.device)\n",
    "print(\"c.device = %s\" % c.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try 2D convolution : \n",
    "### 1. *torch.conv2d*\n",
    "with kernel and bias provided from outside\n",
    "### 2. *torch.nn.Conv2d*\n",
    "***CLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)***  \n",
    "directly produce a callable functor with <torch.nn.Conv2d>.weight and <torch.nn.Conv2d>.bias as kernel and bias\n",
    "### 3. *torch.nn.functional.conv2d*\n",
    "***torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros') → Tensor***  \n",
    "provide kernel and bias from outside\n",
    "### Follow the shape convention :\n",
    "#### Input: (N, C_{in}, H_{in}, W_{in})\n",
    "#### Output: (N, C_{out}, H_{out}, W_{out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2d in module torch.nn.modules.conv:\n",
      "\n",
      "class Conv2d(_ConvNd)\n",
      " |  Applies a 2D convolution over an input signal composed of several input\n",
      " |  planes.\n",
      " |  \n",
      " |  In the simplest case, the output value of the layer with input size\n",
      " |  :math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
      " |  can be precisely described as:\n",
      " |  \n",
      " |  .. math::\n",
      " |      \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
      " |      \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
      " |  \n",
      " |  \n",
      " |  where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
      " |  :math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
      " |  :math:`H` is a height of input planes in pixels, and :math:`W` is\n",
      " |  width in pixels.\n",
      " |  \n",
      " |  * :attr:`stride` controls the stride for the cross-correlation, a single\n",
      " |    number or a tuple.\n",
      " |  \n",
      " |  * :attr:`padding` controls the amount of implicit zero-paddings on both\n",
      " |    sides for :attr:`padding` number of points for each dimension.\n",
      " |  \n",
      " |  * :attr:`dilation` controls the spacing between the kernel points; also\n",
      " |    known as the à trous algorithm. It is harder to describe, but this `link`_\n",
      " |    has a nice visualization of what :attr:`dilation` does.\n",
      " |  \n",
      " |  * :attr:`groups` controls the connections between inputs and outputs.\n",
      " |    :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
      " |    :attr:`groups`. For example,\n",
      " |  \n",
      " |      * At groups=1, all inputs are convolved to all outputs.\n",
      " |      * At groups=2, the operation becomes equivalent to having two conv\n",
      " |        layers side by side, each seeing half the input channels,\n",
      " |        and producing half the output channels, and both subsequently\n",
      " |        concatenated.\n",
      " |      * At groups= :attr:`in_channels`, each input channel is convolved with\n",
      " |        its own set of filters, of size:\n",
      " |        :math:`\\left\\lfloor\\frac{C_\\text{out}}{C_\\text{in}}\\right\\rfloor`.\n",
      " |  \n",
      " |  The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
      " |  \n",
      " |      - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
      " |      - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
      " |        and the second `int` for the width dimension\n",
      " |  \n",
      " |  .. note::\n",
      " |  \n",
      " |       Depending of the size of your kernel, several (of the last)\n",
      " |       columns of the input might be lost, because it is a valid `cross-correlation`_,\n",
      " |       and not a full `cross-correlation`_.\n",
      " |       It is up to the user to add proper padding.\n",
      " |  \n",
      " |  .. note::\n",
      " |  \n",
      " |      When `groups == in_channels` and `out_channels == K * in_channels`,\n",
      " |      where `K` is a positive integer, this operation is also termed in\n",
      " |      literature as depthwise convolution.\n",
      " |  \n",
      " |      In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`,\n",
      " |      a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments\n",
      " |      :math:`(in\\_channels=C_{in}, out\\_channels=C_{in} \\times K, ..., groups=C_{in})`.\n",
      " |  \n",
      " |  .. include:: cudnn_deterministic.rst\n",
      " |  \n",
      " |  Args:\n",
      " |      in_channels (int): Number of channels in the input image\n",
      " |      out_channels (int): Number of channels produced by the convolution\n",
      " |      kernel_size (int or tuple): Size of the convolving kernel\n",
      " |      stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
      " |      padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
      " |      dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
      " |      groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n",
      " |      bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n",
      " |      - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n",
      " |  \n",
      " |        .. math::\n",
      " |            H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
      " |                      \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
      " |  \n",
      " |        .. math::\n",
      " |            W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
      " |                      \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight (Tensor): the learnable weights of the module of shape\n",
      " |                       (out_channels, in_channels, kernel_size[0], kernel_size[1]).\n",
      " |                       The values of these weights are sampled from\n",
      " |                       :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      " |                       :math:`k = \\frac{1}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
      " |      bias (Tensor):   the learnable bias of the module of shape (out_channels). If :attr:`bias` is ``True``,\n",
      " |                       then the values of these weights are\n",
      " |                       sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      " |                       :math:`k = \\frac{1}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> # With square kernels and equal stride\n",
      " |      >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
      " |      >>> # non-square kernels and unequal stride and with padding\n",
      " |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
      " |      >>> # non-square kernels and unequal stride and with padding and dilation\n",
      " |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
      " |      >>> input = torch.randn(20, 16, 50, 100)\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  .. _cross-correlation:\n",
      " |      https://en.wikipedia.org/wiki/Cross-correlation\n",
      " |  \n",
      " |  .. _link:\n",
      " |      https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2d\n",
      " |      _ConvNd\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  forward(self, input)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _ConvNd:\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  reset_parameters(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _ConvNd:\n",
      " |  \n",
      " |  __constants__ = ['stride', 'padding', 'dilation', 'groups', 'bias']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          parameter (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`torch-nn-init`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |                  print(m)\n",
      " |                  if type(m) == nn.Linear:\n",
      " |                      m.weight.data.fill_(1.0)\n",
      " |                      print(m.weight)\n",
      " |      \n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  buffers(self, recurse=True)\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf.data), buf.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |          1 -> Linear (2 -> 2)\n",
      " |  \n",
      " |  named_buffers(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear (2 -> 2))\n",
      " |  \n",
      " |  named_parameters(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse=True)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None\n",
      " |      \n",
      " |      The hook should not modify the input or output.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None\n",
      " |      \n",
      " |      The hook should not modify the input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          parameter (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[[ 0,  0,  0],\n",
      "         [ 9, 16,  2],\n",
      "         [ 6,  6,  6],\n",
      "         [ 1,  1,  0],\n",
      "         [ 0,  0, 12]],\n",
      "\n",
      "        [[10,  0,  0],\n",
      "         [ 0,  1, 11],\n",
      "         [ 8, 19,  0],\n",
      "         [ 0,  4,  0],\n",
      "         [14, 14,  9]],\n",
      "\n",
      "        [[ 9,  1, 21],\n",
      "         [ 7,  0,  2],\n",
      "         [ 0, 19,  0],\n",
      "         [ 0,  0, 10],\n",
      "         [ 0, 11,  0]],\n",
      "\n",
      "        [[ 6,  0,  8],\n",
      "         [ 0,  0,  0],\n",
      "         [ 0,  0,  8],\n",
      "         [ 2,  1,  1],\n",
      "         [ 0,  0,  0]]], dtype=torch.int32)\n",
      "After permute : x = tensor([[[ 0,  9,  6,  1,  0],\n",
      "         [10,  0,  8,  0, 14],\n",
      "         [ 9,  7,  0,  0,  0],\n",
      "         [ 6,  0,  0,  2,  0]],\n",
      "\n",
      "        [[ 0, 16,  6,  1,  0],\n",
      "         [ 0,  1, 19,  4, 14],\n",
      "         [ 1,  0, 19,  0, 11],\n",
      "         [ 0,  0,  0,  1,  0]],\n",
      "\n",
      "        [[ 0,  2,  6,  0, 12],\n",
      "         [ 0, 11,  0,  0,  9],\n",
      "         [21,  2,  0, 10,  0],\n",
      "         [ 8,  0,  8,  1,  0]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.relu( torch.randn((4,5,3)) * 10 )\n",
    "x = x.type(torch.int32)\n",
    "print('x = %s' % x)\n",
    "\n",
    "# reshape to N, C, H, W \n",
    "x = x.permute(2, 0, 1) # or use <tensor>.transpose(<axis-1>, <axis-2>) ?\n",
    "print('After permute : x = %s' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5, 1])\n",
      "Add new axis : x = tensor([[[[ 0,  9,  6,  1,  0],\n",
      "          [10,  0,  8,  0, 14],\n",
      "          [ 9,  7,  0,  0,  0],\n",
      "          [ 6,  0,  0,  2,  0]],\n",
      "\n",
      "         [[ 0, 16,  6,  1,  0],\n",
      "          [ 0,  1, 19,  4, 14],\n",
      "          [ 1,  0, 19,  0, 11],\n",
      "          [ 0,  0,  0,  1,  0]],\n",
      "\n",
      "         [[ 0,  2,  6,  0, 12],\n",
      "          [ 0, 11,  0,  0,  9],\n",
      "          [21,  2,  0, 10,  0],\n",
      "          [ 8,  0,  8,  1,  0]]]], dtype=torch.int32), has shape torch.Size([1, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# expand axis to make first dimension as batch axis\n",
    "x = x[:,:,:, None]\n",
    "print(x.shape)\n",
    "x = x.permute(3, 0, 1, 2)\n",
    "\n",
    "print('Add new axis : x = %s, has shape %s' % (x, x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2 = tensor([[[[ 2.4120,  3.5910,  3.0876,  1.3106,  3.2127],\n",
      "          [ 5.4936,  1.0632,  0.0268,  3.5369,  0.0541],\n",
      "          [ 0.5174,  2.0886,  0.3250,  4.2243, -2.9563],\n",
      "          [-2.1012,  1.2165,  0.1053, -2.6177, -2.0330]],\n",
      "\n",
      "         [[ 2.0123, -0.4714, -6.2841, -2.0067, -1.8003],\n",
      "          [ 3.1480, -5.8397, -5.4140,  1.1358, -2.0245],\n",
      "          [-0.9431,  0.8080,  0.2511, -8.0247,  0.5102],\n",
      "          [ 2.0007,  3.4866, -2.7398,  0.1506,  1.2076]],\n",
      "\n",
      "         [[-3.6319,  1.8007,  4.2506, -0.3342,  1.3977],\n",
      "          [ 1.0782,  6.3760, -1.0772, -5.9988,  3.2720],\n",
      "          [ 1.1935, -6.4391,  2.8020,  1.7751, -0.2542],\n",
      "          [ 0.2959, -1.4613,  1.7441, -1.6855,  2.5792]],\n",
      "\n",
      "         [[-4.1246, -3.1700,  1.4920, -3.4762,  2.1937],\n",
      "          [-0.2022, -4.8056, -1.5206, -3.6980,  5.7713],\n",
      "          [ 1.0800, -5.1590, -0.4570, -2.8144, -1.2044],\n",
      "          [ 3.6611, -1.4142, -2.2824,  1.6976,  0.5922]]]],\n",
      "       grad_fn=<ThnnConv2DBackward>) of shape torch.Size([1, 4, 4, 5])\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.1270, -0.0585,  0.0434],\n",
      "          [-0.1261, -0.1770, -0.0074],\n",
      "          [-0.0729,  0.0047, -0.0216]],\n",
      "\n",
      "         [[-0.1762, -0.0763,  0.1767],\n",
      "          [ 0.1225,  0.0870,  0.0632],\n",
      "          [-0.0861,  0.1322,  0.1117]],\n",
      "\n",
      "         [[-0.1094, -0.0587,  0.0293],\n",
      "          [-0.0617,  0.0428,  0.1094],\n",
      "          [-0.0354,  0.1154,  0.0907]]],\n",
      "\n",
      "\n",
      "        [[[-0.0613,  0.0107, -0.0868],\n",
      "          [-0.1138,  0.1169,  0.1291],\n",
      "          [-0.1701,  0.0531, -0.0217]],\n",
      "\n",
      "         [[-0.1276, -0.0313,  0.0272],\n",
      "          [-0.0689, -0.0553,  0.0432],\n",
      "          [ 0.1097, -0.1680, -0.0321]],\n",
      "\n",
      "         [[ 0.1728,  0.1524, -0.1193],\n",
      "          [ 0.0854, -0.1444, -0.0493],\n",
      "          [-0.1139,  0.1391, -0.0251]]],\n",
      "\n",
      "\n",
      "        [[[-0.1479,  0.0246,  0.1718],\n",
      "          [ 0.0049,  0.1727, -0.1240],\n",
      "          [-0.0139,  0.0514,  0.0210]],\n",
      "\n",
      "         [[ 0.0382,  0.1686, -0.0050],\n",
      "          [-0.0207, -0.0155, -0.1613],\n",
      "          [-0.0589,  0.0495,  0.1635]],\n",
      "\n",
      "         [[ 0.0777, -0.1404, -0.0940],\n",
      "          [-0.1891,  0.0819, -0.0327],\n",
      "          [ 0.1520, -0.0994, -0.0633]]],\n",
      "\n",
      "\n",
      "        [[[-0.0659, -0.1178,  0.0225],\n",
      "          [ 0.0715,  0.1374, -0.0585],\n",
      "          [-0.0972,  0.0509, -0.0661]],\n",
      "\n",
      "         [[ 0.1181, -0.0752, -0.1918],\n",
      "          [-0.0816,  0.0028, -0.1616],\n",
      "          [ 0.0755, -0.0462, -0.1520]],\n",
      "\n",
      "         [[ 0.1329,  0.1540, -0.1255],\n",
      "          [-0.0537,  0.0936,  0.0437],\n",
      "          [ 0.1818,  0.0700, -0.1401]]]], requires_grad=True) Parameter containing:\n",
      "tensor([0.0923, 0.0346, 0.1479, 0.0833], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# torch.conv2d\n",
    "# torch.nn.Conv2d\n",
    "# torch.nn.functional.conv2d\n",
    "# torch.nn.functional.conv_transpose2d\n",
    "\n",
    "# torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "x = x.type(torch.float32)\n",
    "# x = x.to(device)\n",
    "c1 = nn.Conv2d(x.shape[1], 4, 3, stride=(1,1), padding = (1,1))\n",
    "x2 = c1( x )\n",
    "print(\"x2 = %s of shape %s\" % (x2, x2.shape))\n",
    "print(c1.weight, c1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function conv2d:\n",
      "\n",
      "conv2d(...)\n",
      "    conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n",
      "    \n",
      "    Applies a 2D convolution over an input image composed of several input\n",
      "    planes.\n",
      "    \n",
      "    See :class:`~torch.nn.Conv2d` for details and output shape.\n",
      "    \n",
      "    .. include:: cudnn_deterministic.rst\n",
      "    \n",
      "    Args:\n",
      "        input: input tensor of shape :math:`(\\text{minibatch} \\times \\text{in\\_channels} \\times iH \\times iW)`\n",
      "        weight: filters of shape :math:`(\\text{out\\_channels} \\times \\frac{\\text{in\\_channels}}{\\text{groups}} \\times kH \\times kW)`\n",
      "        bias: optional bias tensor of shape :math:`(\\text{out\\_channels})`. Default: ``None``\n",
      "        stride: the stride of the convolving kernel. Can be a single number or a\n",
      "          tuple `(sH, sW)`. Default: 1\n",
      "        padding: implicit zero paddings on both sides of the input. Can be a\n",
      "          single number or a tuple `(padH, padW)`. Default: 0\n",
      "        dilation: the spacing between kernel elements. Can be a single number or\n",
      "          a tuple `(dH, dW)`. Default: 1\n",
      "        groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "          number of groups. Default: 1\n",
      "    \n",
      "    Examples::\n",
      "    \n",
      "        >>> # With square kernels and equal stride\n",
      "        >>> filters = torch.randn(8,4,3,3)\n",
      "        >>> inputs = torch.randn(1,4,5,5)\n",
      "        >>> F.conv2d(inputs, filters, padding=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = tensor([[[[-0.0089, -0.1547,  0.0081],\n",
      "          [ 0.0798, -0.1043,  0.3239],\n",
      "          [ 0.2929,  0.0033, -0.0281]],\n",
      "\n",
      "         [[ 0.0370, -0.4227,  0.3668],\n",
      "          [-0.0281, -0.0059, -0.1393],\n",
      "          [ 0.2590,  0.0742, -0.0212]],\n",
      "\n",
      "         [[ 0.2148,  0.1024,  0.0432],\n",
      "          [-0.0022,  0.1501,  0.0541],\n",
      "          [ 0.0455, -0.1562, -0.2283]]],\n",
      "\n",
      "\n",
      "        [[[-0.1780, -0.1513, -0.0897],\n",
      "          [-0.0051, -0.0051,  0.2008],\n",
      "          [-0.0097,  0.0056, -0.1096]],\n",
      "\n",
      "         [[-0.4929, -0.0220, -0.1346],\n",
      "          [-0.0460, -0.0052,  0.0097],\n",
      "          [-0.0675,  0.1066,  0.2846]],\n",
      "\n",
      "         [[ 0.1029, -0.0240,  0.0096],\n",
      "          [-0.0547, -0.0583, -0.3137],\n",
      "          [ 0.1493,  0.1693,  0.2812]]],\n",
      "\n",
      "\n",
      "        [[[-0.0091,  0.0625, -0.0642],\n",
      "          [-0.0514, -0.0309,  0.0893],\n",
      "          [ 0.0120,  0.0693,  0.1885]],\n",
      "\n",
      "         [[ 0.0630, -0.0112, -0.1684],\n",
      "          [-0.1805,  0.0754, -0.2252],\n",
      "          [-0.1293,  0.1179, -0.3479]],\n",
      "\n",
      "         [[ 0.4887, -0.4296, -0.0903],\n",
      "          [ 0.2439,  0.0736, -0.1106],\n",
      "          [-0.2601, -0.0381,  0.2593]]],\n",
      "\n",
      "\n",
      "        [[[-0.0989, -0.2423, -0.0146],\n",
      "          [-0.1983, -0.3101,  0.0131],\n",
      "          [ 0.0141, -0.1170,  0.1331]],\n",
      "\n",
      "         [[ 0.1194, -0.0352,  0.2272],\n",
      "          [-0.1980,  0.3467, -0.1359],\n",
      "          [-0.0291,  0.0552, -0.0186]],\n",
      "\n",
      "         [[ 0.1753,  0.0686,  0.1254],\n",
      "          [ 0.0319,  0.1216,  0.0819],\n",
      "          [-0.1565, -0.1032, -0.0055]]],\n",
      "\n",
      "\n",
      "        [[[-0.1022, -0.0929, -0.2110],\n",
      "          [-0.4890,  0.2818,  0.0550],\n",
      "          [-0.0154, -0.0409, -0.2817]],\n",
      "\n",
      "         [[ 0.0683, -0.2216, -0.0317],\n",
      "          [-0.3523, -0.3037,  0.1733],\n",
      "          [ 0.1481,  0.1510,  0.0172]],\n",
      "\n",
      "         [[ 0.1647, -0.3003, -0.2353],\n",
      "          [ 0.1715, -0.0245,  0.1063],\n",
      "          [ 0.1994,  0.2711, -0.0866]]]])\n",
      "torch.Size([5, 3, 3, 3])\n",
      "x3 = tensor([[[[  0.1040,  -1.8230,   7.6763],\n",
      "          [  5.5098,  -5.9738,   4.3008]],\n",
      "\n",
      "         [[  6.8076,  -6.3725,  -0.7372],\n",
      "          [ -3.1649,  -3.2087, -13.8009]],\n",
      "\n",
      "         [[-17.2912,   6.5842, -10.8784],\n",
      "          [ -8.3449,   5.4893, -10.0227]],\n",
      "\n",
      "         [[ -7.9198,   4.8254,  -4.3336],\n",
      "          [ -3.1023,   5.8484,  -0.1335]],\n",
      "\n",
      "         [[ -4.8029,  -2.4220,  -4.3067],\n",
      "          [ -1.9634,  -9.4506,  -9.0176]]]]) of shape torch.Size([1, 5, 2, 3])\n",
      "x4 = tensor([[[[  0.1040,   7.6763]],\n",
      "\n",
      "         [[  6.8076,  -0.7372]],\n",
      "\n",
      "         [[-17.2912, -10.8784]],\n",
      "\n",
      "         [[ -7.9198,  -4.3336]],\n",
      "\n",
      "         [[ -4.8029,  -4.3067]]]]) of shape torch.Size([1, 5, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "k_out_channel, k_in_channel, k_w, k_h = 5, x.shape[1], 3, 3\n",
    "kernel = torch.zeros((k_out_channel, k_in_channel, k_w, k_h))\n",
    "kernel = torch.nn.init.xavier_normal_(kernel)\n",
    "print(\"kernel = %s\" % kernel)\n",
    "print(kernel.shape)\n",
    "\n",
    "x3 = torch.conv2d( x, kernel )\n",
    "print(\"x3 = %s of shape %s\" % (x3, x3.shape))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "# torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros') → Tensor\n",
    "x4 = F.conv2d(x, kernel, stride = (2, 2))\n",
    "print(\"x4 = %s of shape %s\" % (x4, x4.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
